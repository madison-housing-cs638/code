{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import random\n",
    "import datetime\n",
    "import dateparser\n",
    "import re\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600963353.930058"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manualScrapeNameAddress(html):\n",
    "    # Why does this exist? Becasue:\n",
    "    # <div class=\"clearfix\">\n",
    "    # <h2>Owner(s)</h3> ... </div>\n",
    "    # Somehow, the html is formated wrong, so beautiful soup doesnt want to play nice with it. \n",
    "    htmlNoLines = html.replace('\\n', '')\n",
    "    htmlNoLines = htmlNoLines.replace('\\r', '')\n",
    "    htmlNoLines = htmlNoLines.replace('\\t', '')\n",
    "    \n",
    "    groups = re.findall('<div class=\"clearfix\">(\\s+)(<h2>Owner(.*))<\\/div>', htmlNoLines)\n",
    "    ownerInfo = groups[0][1]\n",
    "    try:\n",
    "        lastDivLocation = ownerInfo.index('</div>')\n",
    "        relavent = ownerInfo[:lastDivLocation]\n",
    "        firstParagraph = relavent.index('<p>')\n",
    "        nameAddress = relavent[firstParagraph:] #<p>Name</p> <p>Address</p>\n",
    "        \n",
    "        lilSoup = BeautifulSoup(nameAddress)\n",
    "        paragraphs = lilSoup.find_all('p')\n",
    "        return (paragraphs[0].text.strip(), paragraphs[1].text.strip())\n",
    "    except Exception as e:\n",
    "        print(html)\n",
    "        print(e)\n",
    "        return ('X', 'X')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HomeSaleRecord:\n",
    "    def __init__(self, parcelId, grantorName, granteeName, date, kind, price, included):\n",
    "        self.parcelId = parcelId\n",
    "        self.grantorName = grantorName\n",
    "        self.granteeName = granteeName\n",
    "        self.date = date\n",
    "        self.kind = kind\n",
    "        self.price = price\n",
    "        self.included = included\n",
    "        \n",
    "    def __str__(self):\n",
    "        firstLine = f'parcel: {self.parcelId}, date: {self.date}, grantor: {self.grantorName}, grantee: {self.granteeName}'\n",
    "        secondLine = f'price: {self.price}, kind: {self.kind}, included: {self.included}'\n",
    "        return firstLine + '\\n' + secondLine\n",
    "    \n",
    "    def __repr__(self):\n",
    "        firstLine = f'parcel: {self.parcelId}, date: {self.date}, grantor: {self.grantorName}, grantee: {self.granteeName}'\n",
    "        secondLine = f'price: {self.price}, kind: {self.kind}, included: {self.included}'\n",
    "        return firstLine + '\\n' + secondLine\n",
    "    \n",
    "    def serialize(self):\n",
    "        return {\n",
    "            \"Parcel\": self.parcelId,\n",
    "            \"Date\": self.date,\n",
    "            \"Buyer\": self.granteeName,\n",
    "            \"Seller\": self.grantorName,\n",
    "            \"Price\": self.price,\n",
    "            \"Kind\": self.kind,\n",
    "            \"Conveyance_Included\": self.included\n",
    "        }\n",
    "\n",
    "class TaxAssessmentRecord:\n",
    "    def __init__(self, parcelId, year, land, improvements, total):\n",
    "        self.parcelId = parcelId\n",
    "        self.year = year\n",
    "        self.land = land\n",
    "        self.improvements = improvements\n",
    "        self.total = total\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f'parcel: {self.parcelId}, {self.year}, Land: {self.land}, Improvements: {self.improvements}, Total: {self.total}'\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'parcel: {self.parcelId}, {self.year}, Land: {self.land}, Improvements: {self.improvements}, Total: {self.total}'\n",
    "    \n",
    "    def serialize(self):\n",
    "        return {\n",
    "            \"Parcel\": self.parcelId,\n",
    "            \"Year\": self.year,\n",
    "            \"Land_Assessment\": self.land,\n",
    "            \"Improvement_Assessment\": self.improvements,\n",
    "            \"Total_Assessment\": self.total,\n",
    "        }\n",
    "    \n",
    "\n",
    "def moneyStringToInt(moneyString):\n",
    "    return int(moneyString.replace('$', '').replace(',', ''))\n",
    "\n",
    "def moneyStringToFloat(moneyString):\n",
    "    return float(moneyString.replace('$', '').replace(',', ''))\n",
    "        \n",
    "def getTaxAssessmentRecords(html_soup, parcelId):   \n",
    "    tables = html_soup.find_all('table')\n",
    "    propertyValueTable = list(filter(lambda t: 'Property Value' in t.text, tables))[0]\n",
    "    propertyValueTableRows = propertyValueTable.find('tbody').find_all('tr')\n",
    "\n",
    "    records = []\n",
    "    for i in range(1, len(propertyValueTableRows)):\n",
    "        tr = propertyValueTableRows[i]\n",
    "        rowDatas = tr.find_all('td') \n",
    "\n",
    "        year = int(rowDatas[0].text.strip())\n",
    "        \n",
    "        land = moneyStringToInt(rowDatas[1].text.strip())\n",
    "        improvments = moneyStringToInt(rowDatas[2].text.strip())\n",
    "        total = moneyStringToInt(rowDatas[3].text.strip())\n",
    "        record = TaxAssessmentRecord(parcelId, year, land, improvments, total)\n",
    "        records.append(record)\n",
    "    return records\n",
    "\n",
    "def getMostRecentTaxAssessmentRecord(html_soup, parcelId):\n",
    "    records = getTaxAssessmentRecords(html_soup, parcelId)\n",
    "    return list(sorted(records, key=lambda taxRecord: taxRecord.year))[0]\n",
    "           \n",
    "    \n",
    "def tryParseDate(dateString):\n",
    "    try:\n",
    "        return datetime.datetime.strptime(dateInput, '%m/%Y').date().isoformat()\n",
    "    except:\n",
    "        return '1900-01-01'\n",
    "        \n",
    "    \n",
    "def getSalesRecordFromTable(tableElem, parcelId):\n",
    "    # grantorName, granteeName, date, kind, price, included\n",
    "    rows = tableElem.find_all('tr')\n",
    "    grantor = rows[0].find('td').text.strip()\n",
    "    grantee = rows[1].find('td').text.strip()\n",
    "    \n",
    "    thirdRowDatas = rows[2].find_all('td')\n",
    "    dateInput = thirdRowDatas[0].text.strip()\n",
    "    dateFormated = tryParseDate(dateInput)\n",
    "    \n",
    "    priceStr = thirdRowDatas[1].text.strip()\n",
    "    price = moneyStringToFloat(priceStr)\n",
    "    \n",
    "    fourthRowDatas = rows[3].find_all('td')\n",
    "    kind  = fourthRowDatas[0].text.strip()\n",
    "    included = fourthRowDatas[1].text.strip()\n",
    "    \n",
    "    return HomeSaleRecord(parcelId, grantor, grantee, dateFormated, kind, price, included)\n",
    "    \n",
    "\n",
    "def getSalesRecords(html_soup, parcelId):\n",
    "    table = html_soup.find('table')\n",
    "    tableBodies = table.find_all('tbody')\n",
    "    return [getSalesRecordFromTable(body, parcelId) for body in tableBodies]\n",
    "\n",
    "\n",
    "def hasPropertyDetails(html_soup):\n",
    "    if('No data was found for this property.' in html_soup.text):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def hasPropertySalesDetails(html_soup):\n",
    "    if('No conveyance information is available online' in html_soup.text):\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2015-09-01'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = '9/2015'\n",
    "ope = datetime.datetime.strptime(d, '%m/%Y')\n",
    "dir(ope.date())\n",
    "ope.date().isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllParcelIds():\n",
    "    with open('all_parcel_ids.txt') as f:\n",
    "        return f.readlines()\n",
    "    return result\n",
    "\n",
    "def getPropertyDetailsUrl(parcelId):\n",
    "    return f'https://www.cityofmadison.com/assessor/property/propertydata.cfm?ParcelN={str(parcelId)}'\n",
    "\n",
    "def getPropertySalesUrl(parcelId):\n",
    "    #return f'https://www.cityofmadison.com/assessor/property/propertydata.cfm?ParcelN=0{str(parcelId)}&Type=S'\n",
    "    return f'https://www.cityofmadison.com/assessor/property/additionalpropertydata.cfm?ParcelN={str(parcelId)}&Type=S'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "BATCH COMPLETE\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "BATCH COMPLETE\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "BATCH COMPLETE\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "BATCH COMPLETE\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "BATCH COMPLETE\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "BATCH COMPLETE\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "BATCH COMPLETE\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "BATCH COMPLETE\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "BATCH COMPLETE\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "BATCH COMPLETE\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "BATCH COMPLETE\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "BATCH COMPLETE\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "BATCH COMPLETE\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "BATCH COMPLETE\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "BATCH COMPLETE\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "BATCH COMPLETE\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "BATCH COMPLETE\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "BATCH COMPLETE\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "BATCH COMPLETE\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "BATCH COMPLETE\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "BATCH COMPLETE\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "BATCH COMPLETE\n",
      "\n",
      "BATCH COMPLETE\n",
      "\n",
      "BATCH COMPLETE\n",
      "\n",
      "BATCH COMPLETE\n",
      "1379.0853326320648\n"
     ]
    }
   ],
   "source": [
    "# Read in unproccessed ids and processed ids\n",
    "# Sample some ids from unproccessed ids\n",
    "# Get 3 dataframes from those ids:\n",
    "#     * All Sales\n",
    "#     * All Tax Assessment Info\n",
    "#     * ID --> Name\n",
    "# Load the existing version of those dataframes\n",
    "# Combine with the three new dataframes\n",
    "# Save those 3 new, larger dataframes to memory, replacing the previos versions. \n",
    "# Save ids_unprocessed and ids_processed with the new versions of each.\n",
    "\n",
    "def readfileAsSet(filename):\n",
    "    with open(filename) as f:\n",
    "        lines_clipped = [l.strip() for l in f.readlines()]\n",
    "        return set(lines_clipped)\n",
    "    \n",
    "def writeSetToFile(filename, setToWrite):\n",
    "    items = list(setToWrite)\n",
    "    output = \"\\n\".join(items)\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(output)\n",
    "\n",
    "def processParcel(parcel_id, pool_manager):\n",
    "    # Name, Most Recent TaxAssessment, List of Sales Info\n",
    "    result = (None, None, None)\n",
    "    \n",
    "    details_url = getPropertyDetailsUrl(parcel_id)\n",
    "    details_html = pool_manager.request('GET', details_url, preload_content=True).data.decode('utf-8')\n",
    "    details_soup = BeautifulSoup(details_html)\n",
    "    if(hasPropertyDetails(details_soup)):\n",
    "        name, addr = manualScrapeNameAddress(details_html)\n",
    "        taxAssessment = getMostRecentTaxAssessmentRecord(details_soup, parcel_id)\n",
    "        result = (name, taxAssessment, None)\n",
    "    \n",
    "    \n",
    "    sales_url = getPropertySalesUrl(parcel_id)\n",
    "    sales_html = pool_manager.request('GET', sales_url, preload_content=True).data.decode('utf-8')\n",
    "    sales_soup = BeautifulSoup(sales_html)\n",
    "    if(hasPropertySalesDetails(sales_soup)):\n",
    "        sales = getSalesRecords(sales_soup, parcel_id)\n",
    "        itemA = result[0]\n",
    "        itemB = result[1]\n",
    "        result = (itemA, itemB, sales)\n",
    "\n",
    "    return result\n",
    "\n",
    "def processNParcels(n):\n",
    "    http = urllib3.PoolManager()\n",
    "    batch_size = 100\n",
    "    num_batches = math.ceil(n / batch_size)\n",
    "    \n",
    "    for b in range(num_batches):\n",
    "        ids_unprocessed = readfileAsSet('ids_unprocessed.txt')\n",
    "        ids_processed = readfileAsSet('ids_processed.txt')\n",
    "        df_names = pd.read_csv('parcel_names.csv')\n",
    "        df_names.set_index(\"Parcel\")\n",
    "        df_assessments = pd.read_csv('parcel_assessments.csv')\n",
    "        df_assessments.set_index(\"Parcel\")\n",
    "        df_sales = pd.read_csv('parcel_sales.csv')\n",
    "        df_sales.set_index(\"Parcel\")\n",
    "        \n",
    "        num_ids_to_sample = min(batch_size, len(ids_unprocessed))\n",
    "        target_ids = random.sample(ids_unprocessed, num_ids_to_sample)\n",
    "        \n",
    "        for parcel_id in target_ids:\n",
    "            print(\"|\", end = \"\")\n",
    "            owners_names, taxAssessment, homeSales = processParcel(parcel_id, http)\n",
    "            \n",
    "            # Names\n",
    "            if(owners_names is not None):\n",
    "                name_record = {\"Parcel\": parcel_id, \"Owners\": owners_names}\n",
    "                df_names = df_names.append(name_record, ignore_index = True)\n",
    "                \n",
    "            # Tax Assessments\n",
    "            if(taxAssessment is not None):\n",
    "                df_assessments = df_assessments.append(taxAssessment.serialize(), ignore_index = True)\n",
    "            \n",
    "            # Home Sales\n",
    "            if(homeSales is not None):\n",
    "                for sale in homeSales:\n",
    "                    df_sales = df_sales.append(sale.serialize(), ignore_index = True)\n",
    "                    \n",
    "        df_names.to_csv('parcel_names.csv', index=False)\n",
    "        df_assessments.to_csv('parcel_assessments.csv', index=False)\n",
    "        df_sales.to_csv('parcel_sales.csv', index=False)\n",
    "        \n",
    "        just_processed_ids = set(target_ids)\n",
    "        new_processed_ids = ids_processed.union(just_processed_ids)\n",
    "        new_unprocessed_ids = ids_unprocessed.difference(just_processed_ids)\n",
    "        \n",
    "        writeSetToFile('ids_processed.txt', new_processed_ids)\n",
    "        writeSetToFile('ids_unprocessed.txt', new_unprocessed_ids)\n",
    "        print('\\nBATCH COMPLETE')\n",
    "    \n",
    "    \n",
    "#df_names = pd.read_csv('parcel_names.csv')\n",
    "#df_assessments = pd.read_csv('parcel_assessments.csv')\n",
    "#df_sales = pd.read_csv('parcel_sales.csv')\n",
    "\n",
    "before = time.time()\n",
    "processNParcels(2500)\n",
    "after = time.time()\n",
    "\n",
    "print(after - before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = None\n",
    "#df_test = pd.DataFrame(columns = [\"ID\", \"Name\"])\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_test.set_index('ID')\n",
    "df_test = df_test.append({\"ID\": \"A1\", \"Name\": \"Ben\"}, ignore_index = True)\n",
    "df_test.to_csv('test.csv', index = False)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('allParcelIds.txt') as file_all:\n",
    "    ids = ['0'+ ID.strip() for ID in file_all.readlines()]\n",
    "    newContents = '\\n'.join(ids)\n",
    "    with open('all_parcel_ids.txt', 'w') as file_new:\n",
    "        file_new.write(newContents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'date' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-163-1e3aba9a7a16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'date' is not defined"
     ]
    }
   ],
   "source": [
    "tuple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = set()\n",
    "s.add('one')\n",
    "s.add('two')\n",
    "writeSetToFile('boi.txt', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
